{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.17.2.tar.gz (1.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gym) (1.18.5)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "Collecting cloudpickle<1.4.0,>=1.2.0\n",
      "  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: future in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.17.2-py3-none-any.whl size=1650896 sha256=2d762dfbd38add8b5dcfdaa4d7df3050c962874248daf3a5fe295292855a6601\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\18\\e1\\58\\89a2aa24e6c2cc800204fc02010612afdf200926c4d6bfe315\n",
      "Successfully built gym\n",
      "Installing collected packages: pyglet, cloudpickle, gym\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.4.1\n",
      "    Uninstalling cloudpickle-1.4.1:\n",
      "      Successfully uninstalled cloudpickle-1.4.1\n",
      "Successfully installed cloudpickle-1.3.0 gym-0.17.2 pyglet-1.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: spyder 4.1.3 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "ERROR: spyder 4.1.3 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "WARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\hp\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment\n",
    "#This environment is the central class in the gym API\n",
    "env=gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02502274, -0.00917571,  0.03893731,  0.04445915])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()   # here the state has been defined by four attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1000):\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space          #action_space is a object of the \"Discrete\" class which basically contains all actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(4,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box is another class in the gym API which is used to represent n-dimensional tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "action=env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=env.step(action)          # step() is a method which executes a particular action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing CartPole using Random Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to play multiple game episodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " game episode:0/20 .High_score: 20\n",
      " game episode:1/20 .High_score: 14\n",
      " game episode:2/20 .High_score: 41\n",
      " game episode:3/20 .High_score: 13\n",
      " game episode:4/20 .High_score: 25\n",
      " game episode:5/20 .High_score: 20\n",
      " game episode:6/20 .High_score: 22\n",
      " game episode:7/20 .High_score: 34\n",
      " game episode:8/20 .High_score: 19\n",
      " game episode:9/20 .High_score: 11\n",
      " game episode:10/20 .High_score: 15\n",
      " game episode:11/20 .High_score: 14\n",
      " game episode:12/20 .High_score: 14\n",
      " game episode:13/20 .High_score: 8\n",
      " game episode:14/20 .High_score: 14\n",
      " game episode:15/20 .High_score: 32\n",
      " game episode:16/20 .High_score: 13\n",
      " game episode:17/20 .High_score: 19\n",
      " game episode:18/20 .High_score: 11\n",
      " game episode:19/20 .High_score: 16\n",
      "all episodes over\n"
     ]
    }
   ],
   "source": [
    "for e in range(20): # e -> episode\n",
    "    # play 20 episodes \n",
    "    observation=env.reset()\n",
    "    #print(observation)\n",
    "    for t in range(50):    # t is the maximum time steps in which the game should be successfully over \n",
    "        env.render()\n",
    "        action=env.action_space.sample()\n",
    "        observation,reward,done,other_info=env.step(action)\n",
    "        if done:\n",
    "            # game episode is over:\n",
    "            print(\" game episode:{}/{} .High_score: {}\".format(e,20,t))\n",
    "            break\n",
    "env.close()\n",
    "print(\"all episodes over\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model,Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Design Exploration Vs explotation tradeoff\n",
    "#AI agent design based on the concept of Q-learning\n",
    "from collection import deque\n",
    "class Agent:\n",
    "    def __init__(self,state_size,action_size):  # state_size is the number of parameters which are defining the state\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory=deque(maxlen=2000)\n",
    "        self.gamma=0.95  # discount factor\n",
    "    \n",
    "        #Exploration vS Exploitation tradeoff\n",
    "        self.epsilon = 1.0 # 100 % random exploration in the beginning\n",
    "        self.epsilon_decay = 0.995   #means the random_exploration will be 99.5% and 0.5% will be the knowledge which the agent has learnt\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon_min = 0.01 # still if you have gained a lot of experience ,it will take 1% random exploration at a particular step\n",
    "        self.model=self._create_model()\n",
    "    \n",
    "    def _create_model(self):\n",
    "        model=Sequential()\n",
    "        model\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
